// Copyright (C) 2009 Google Inc.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// OMeta/JS parser for Ecmascript 5
// @author Tom Van Cutsem

// dependencies of this file: 'unicode.js'

// === A.1 Lexical Grammar (Scanner) ===

// A variant of UnicodeCategories restricted to the ASCII subset of Unicode...
// see the file unicode.js for the real thing
/*var UnicodeCategories = {
    // each function in this object = f(CharCode) -> Boolean
    'ZWNJ' : function(c) { return c ==  0x200C; },
    'ZWJ'  : function(c) { return c ==  0x200D; },
    'TAB'  : function(c) { return c ==  0x0009; },
    'VT'   : function(c) { return c ==  0x000B; },
    'FF'   : function(c) { return c ==  0x000C; },
    'SP'   : function(c) { return c ==  0x0020; },
    'NBSP' : function(c) { return c ==  0x00A0; },
    'BOM'  : function(c) { return c ==  0xFEFF; },
    'USP'  : function(c) { return false; }, // apart from SP and NBSP completely out of ASCII range
    'LF'   : function(c) { return c ==  0x000A; },
    'CR'   : function(c) { return c ==  0x000D; },
    'LS'   : function(c) { return c ==  0x2028; },
    'PS'   : function(c) { return c ==  0x2029; },
    'L'    : function(c) { // L = Lu, Ll, Lt, Lm, Lo
      return (0x0041 <= c && c <= 0x005A) || // Lu
             (0x0061 <= c && c <= 0x007A);  // Ll
      },     //(false) ||  // Lt, completely out of ASCII range
             //(false) ||  // Lm, completely out of ASCII range
             //(false); }, // Lo, completely out of ASCII range
    'Nl'   : function(c) { return false; }, // completely out of ASCII range
    'Mn'   : function(c) { return false; }, // completely out of ASCII range
    'Mc'   : function(c) { return false; }, // completely out of ASCII range
    'Nd'   : function(c) { return 0x0030 <= c && c <= 0x0039; },
    'Pc'   : function(c) { return c == 0x005F; }  // _ is only char in ASCII range
};*/

// Literal tokens are represented as objects of the form { type: String, value: String }
// Literal tokens represent number, string, boolean, null and regular expression literals
function literal(t, val) {
	return { type: t, value: val };
};

// some regular expressions for faster identifier and whitespace parsing
var ucSpacesRE = new RegExp("\\s");

// A.1 Lexical Grammar
ometa LexicalGrammar {

  // input characters are represented as ES3 characters, which can be any unicode character
  SourceCharacter = char,

  // 7: Goal production in contexts where a leading '/' or '/=' is permitted
  // Note: not used by the parser
  InputElementDiv = Whitespace | LineTerminator | Comment | Token | DivPunctuator,

  // 7: Goal production in contexts where a leading '/' or '/=' is not permitted
  // Note: not used by the parser
  InputElementRegExp = Whitespace | LineTerminator | Comment | Token | RegularExpressionLiteral,

  Whitespace = uc('SP') | uc('TAB') | uc('VT') | uc('FF') | uc('NBSP') | uc('BOM') | uc('Zs'),
  LineTerminator = uc('LF') | uc('CR') | uc('LS') | uc('PS'),
  LineTerminatorSequence = uc('LF') | ~uc('LF') uc('CR') | uc('LS') | uc('PS') | uc('CR') uc('LF'),

  Comment = MultiLineComment | SingleLineComment,

  MultiLineComment = seq("/*") (MultiLineCommentChars | empty -> ""):cs seq("*/") -> (cs),
  MultiLineCommentChars = MultiLineNotAsteriskChar:c (MultiLineCommentChars | empty -> ""):cs ->
                          ( c + cs )
                        | '*' (PostAsteriskCommentChars | &seq("*/") -> ""):cs -> ( '*' + cs ),
  PostAsteriskCommentChars = MultiLineNotForwardSlashOrAsteriskChar:c
                             (MultiLineCommentChars | empty -> ""):cs -> ( c + cs )
                           | '*' (PostAsteriskCommentChars | &seq("*/") -> ""):cs -> ( '*' + cs ),
  MultiLineNotAsteriskChar = ~('*') SourceCharacter:c -> (c),
  MultiLineNotForwardSlashOrAsteriskChar = ~('/' | '*') SourceCharacter:c -> (c),
  SingleLineComment = seq("//") (SingleLineCommentChars | empty -> ""):cs -> (cs),
  SingleLineCommentChars = SingleLineCommentChar:c (SingleLineCommentChars | empty -> ""):cs ->
                           (c + cs),
  SingleLineCommentChar = ~LineTerminator SourceCharacter:c -> (c),
  
  // Note: not currently used by the parser
  Token = IdentifierName | Punctuator | NumericLiteral | StringLiteral,

  Identifier = IdentifierName:n ~checkReservedWord(n) -> (n),
  IdentifierName = IdentifierName:first IdentifierPart:rest -> ( first+rest )
                 | IdentifierStart,
  IdentifierStart = UnicodeLetter | '$' | '_' | '\\' UnicodeEscapeSequence,
  IdentifierPart = IdentifierStart | UnicodeCombiningMark
                 | UnicodeDigit | UnicodeConnectorPunctuation
                 | uc('ZWNJ') | uc('ZWJ'),
  UnicodeLetter = uc('L') | uc('Nl'),
  UnicodeCombiningMark = uc('Mn') | uc('Mc'),
  UnicodeDigit = uc('Nd'),
  UnicodeConnectorPunctuation = uc('Pc'),

  checkReservedWord :id = ?(self.isKeyword(id) || self.isFutureReservedWord(id,self.strictmode) ||
                            id == "null" || id == "true" || id == "false") -> (true),

  // Because OMeta/JS currently does not optimize Keyword-like rules using
  // jump tables, such rules can be quite slow. Using firefox's profiler,
  // I measured parsing times for the following expression: "{set y(z) {1}}"
  // and got the following results:
  //   using the regular OMeta rules for Keyword and FutureReservedWord: 1578.443ms, 23287 calls
  //   using the ad hoc rules for Keyword and FutureReservedWord: 1036.422ms, 14779 calls
  // which amounts to ~ 33% speedup

  /*
  ReservedWord = Keyword | FutureReservedWord(self.strictmode) | NullLiteral | BooleanLiteral,

  // Note: keywords that are the complete prefix of another keyword should
  // be prioritized (e.g. 'in' should come before 'instanceof')
  Keyword = (``break''   | ``do''        | ``in''         | ``typeof''
          | ``case''     | ``else''      | ``new''        | ``var''
          | ``catch''    | ``finally''   | ``return''     | ``void''
          | ``continue'' | ``for''       | ``switch''     | ``while''
          | ``debugger'' | ``function''  | ``this''       | ``with''
          | ``default''  | ``if''        | ``throw''
          | ``delete''   | ``instanceof''| ``try''):kwname ~IdentifierPart -> (kwname),*/

  // Alternative (faster) keyword rule
  // Keyword = IdentifierName:n ?(self.isKeyword(n)) -> (n),

  /*FutureReservedWord false:strict = (``class''| ``enum''  | ``extends''| ``super''
                                  |  ``const''| ``export''| ``import''):kwname -> (kwname),
  FutureReservedWord true:strict = FutureReservedWord(false)
                                 | (``implements''| ``let''    | ``private''  | ``public''
                                 |  ``interface'' | ``package''| ``protected''| ``static''
                                 |  ``yield''):kwname -> (kwname),*/

  // Alternative (faster) future reserved word rule
  // Note: rule not currently used by the parser, only by the unit tests
  FutureReservedWord :strict = IdentifierName:n ?(self.isFutureReservedWord(n,strict)) -> n,

  // Note: beware of the ordering of punctuators with a common prefix!
  // OMeta is a PEG, so '|' denotes prioritized choice.
  // E.g. if '+' would come before ``++'' then the string "++5"
  // would be parsed as "+(+(5))" rather than "++(5)"
  // Punctuators comprised of more characters are prioritized
  // Note: this rule are not currently used by the parser
  Punctuator = (``>>>=''
             | ``>>='' | ``>>>'' | ``==='' | ``!==''| ``<<=''
             | ``+=''  | ``-=''  | ``*=''  | ``%='' | ``>=''
             | ``==''  | ``!=''  | ``++''  | ``--'' | ``<<''
             | ``>>''  | ``<=''  | ``&=''  | ``|='' | ``^=''
             | ``&&''  | ``||''
             | '{'     | '}'     | '('     | ')'    | '['   | ']'
             | '.'     | ';'     | ','     | '<'    | '>'   | '!'
             | '~'     | '='     | '&'     | '|'    | '^'   | '?'
             | ':'     | '*'     | '%'     | '+'    | '-'):symbol -> (symbol),
  // Note: this rule are not currently used by the parser
  DivPunctuator = (``/='' | '/'):symbol -> (symbol),

  Literal = NullLiteral | BooleanLiteral | NumericLiteral
          | StringLiteral | RegularExpressionLiteral, // spec forgot Regexp literals in appendix?
  NullLiteral = ``null'' -> (literal("null", null)),
  BooleanLiteral = (``true'' -> true | ``false'' -> false):b -> (literal("boolean",b)),

  // For semantics on how decimal literals are constructed, see section 7.8.3

  // Note that the ordering of HexIntegerLiteral and DecimalLiteral is reversed w.r.t. the spec
  // This is intentional: the order DecimalLiteral | HexIntegerLiteral will parse
  // '0x...' as a decimal literal '0' followed by 'x...'
  NumericLiteral = (HexIntegerLiteral | DecimalLiteral):l -> (literal("number",l)),

  // DecimalLiteral produces objects of the form {val: aNumber, len: aNumber }
  // The 'len' attribute describes the number of characters in the parsed numeral
  // This is required for interpreting fractional literals
  DecimalLiteral = DecimalIntegerLiteral:l '.'
                     (DecimalDigits | empty -> {val:0,len:0}):d (ExponentPart | empty -> 0):e ->
                     ( (l + (d.val * Math.pow(10,-d.len))) * Math.pow(10,e) )
                 | '.' DecimalDigits:d (ExponentPart | empty -> 0):e ->
                     ( (d.val * Math.pow(10, -d.len)) * Math.pow(10,e) )
                 | DecimalIntegerLiteral:l (ExponentPart | empty -> 0):e ->
                     ( l * Math.pow(10,e) ),
  DecimalIntegerLiteral = NonZeroDigit:z (DecimalDigits | empty -> {val:0,len:0}):d ->
                          ( (z * Math.pow(10,d.len)) + d.val )
                        | '0'->0,
  DecimalDigits = DecimalDigits:ds DecimalDigit:d -> ({ val: (ds.val * 10 + d), len: ds.len+1 })
                | DecimalDigit:d -> ({val: d, len: 1}),
  DecimalDigit = '0'->0 | '1'->1 | '2'->2 | '3'->3 | '4'->4 | '5'->5 | '6'->6 | '7'->7 | '8'->8 | '9'->9,
  NonZeroDigit = '1'->1 | '2'->2 | '3'->3 | '4'->4 | '5'->5 | '6'->6 | '7'->7 | '8'->8 | '9'->9,

  ExponentPart = ExponentIndicator SignedInteger:si -> si,
  ExponentIndicator = 'e' | 'E',
  SignedInteger = DecimalDigits:ds -> (ds.val)
                | '+' DecimalDigits:ds -> (ds.val)
                | '-' DecimalDigits:ds -> (-(ds.val)),

  HexIntegerLiteral = HexIntegerLiteral:l HexDigit:d -> ( (l * 16) + d )
                    | ``0x'' HexDigit:d -> (d)
                    | ``0X'' HexDigit:d -> (d),
  HexDigit = '0'->0 | '1'->1 | '2'->2 | '3'->3 | '4'->4 | '5'->5 | '6'->6 | '7'->7 | '8'->8 | '9'->9
           | 'a'->10 | 'b'->11 | 'c'->12 | 'd'->13 | 'e'->14 | 'f'->15
           | 'A'->10 | 'B'->11 | 'C'->12 | 'D'->13 | 'E'->14 | 'F'->15,

  // For semantics on how string literals are constructed, see section 7.8.4
  StringLiteral = '"' (DoubleStringCharacters | empty -> ""):s '"' -> (literal("string",s))
                | '\'' (SingleStringCharacters | empty -> ""):s '\'' -> (literal("string",s)),
  DoubleStringCharacters = DoubleStringCharacter:c (DoubleStringCharacters | empty -> ""):cs ->
                           ( c.concat(cs) ),
  SingleStringCharacters = SingleStringCharacter:c (SingleStringCharacters | empty -> ""):cs ->
                           ( c.concat(cs) ),
  DoubleStringCharacter = ~('"' | '\\' | LineTerminator) SourceCharacter:s -> (s)
                        | '\\' EscapeSequence:s -> (s)
                        | LineContinuation,
  SingleStringCharacter = ~('\'' | '\\' | LineTerminator) SourceCharacter:s -> (s)
                        | '\\' EscapeSequence:s -> (s)
                        | LineContinuation,
  LineContinuation = '\\' LineTerminatorSequence -> (""),
  EscapeSequence = CharacterEscapeSequence
                 | ~DecimalDigit '0' -> ( String.fromCharCode(0000) ) /*\u0000*/
                 | HexEscapeSequence
                 | UnicodeEscapeSequence,
  CharacterEscapeSequence = SingleEscapeCharacter
                          | NonEscapeCharacter,
  SingleEscapeCharacter = '\'' -> ( String.fromCharCode(0039) ) /*\u0027*/
                        | '"'  -> ( String.fromCharCode(0034) ) /*\u0022*/
                        | '\\' -> ( String.fromCharCode(0092) ) /*\u005C*/
                        | 'b'  -> ( String.fromCharCode(0008) ) /*\u0008*/
                        | 'f'  -> ( String.fromCharCode(0012) ) /*\u000C*/
                        | 'n'  -> ( String.fromCharCode(0010) ) /*\u000A*/
                        | 'r'  -> ( String.fromCharCode(0013) ) /*\u000D*/
                        | 't'  -> ( String.fromCharCode(0009) ) /*\u0009*/
                        | 'v'  -> ( String.fromCharCode(0011) ) /*\u000B*/,
  NonEscapeCharacter = ~(EscapeCharacter | LineTerminator) SourceCharacter:s -> (s),
  EscapeCharacter = SingleEscapeCharacter | DecimalDigit | 'x' | 'u',
  HexEscapeSequence = 'x' HexDigit:a HexDigit:b -> ( String.fromCharCode(a*16+b) ),
  UnicodeEscapeSequence = 'u' HexDigit:a HexDigit:b HexDigit:c HexDigit:d ->
                              ( String.fromCharCode(a*4096 + b*256 + c*16 + d) ),

  // section 7.8.5

  // body and flags are left uninterpreted while parsing (they are parsed as strings)
  RegularExpressionLiteral = '/' RegularExpressionBody:b '/' RegularExpressionFlags:f ->
                             ( literal("regexp",{body:b,flags:f}) ),
  RegularExpressionBody = RegularExpressionFirstChar:c RegularExpressionChars:cs -> (c+cs),
  RegularExpressionChars = RegularExpressionChars:cs RegularExpressionChar:c -> (cs+c)
                         | empty -> (""),
  RegularExpressionFirstChar = ~('*' |'\\' | '/' | '[') RegularExpressionNonTerminator
                             | RegularExpressionBackslashSequence
                             | RegularExpressionClass,
  RegularExpressionChar = ~('\\' | '/' | '[') RegularExpressionNonTerminator
                        | RegularExpressionBackslashSequence
                        | RegularExpressionClass,
  RegularExpressionBackslashSequence = '\\' RegularExpressionNonTerminator:nt -> ( "\\"+nt ),
  RegularExpressionNonTerminator = ~(LineTerminator) SourceCharacter,
  RegularExpressionClass = '[' RegularExpressionClassChars:cs ']' -> ("["+cs+"]" ),
  RegularExpressionClassChars = RegularExpressionClassChars:cs RegularExpressionClassChar:c ->
                                ( cs+c )
                              | empty -> (""),
  RegularExpressionClassChar = ~(']' | '\\') RegularExpressionNonTerminator
                             | RegularExpressionBackslashSequence,
  RegularExpressionFlags = RegularExpressionFlags:fs IdentifierPart:f -> ( fs+f )
                         | empty -> (""),

  // === Implementation-level rules (not part of the spec) ===

  // uc(category) -> accepts only unicode characters x that fall within the given unicode category
  uc :id = char:x ?(UnicodeCategories[id].test(x)) -> (x),

  MultiLineCommentNoNL = seq("/*") (MultiLineCommentCharsNoNL | empty -> ""):cs seq("*/") -> (cs),
  MultiLineCommentCharsNoNL = MultiLineNotAsteriskCharNoNL:c (MultiLineCommentCharsNoNL | empty -> ""):cs ->
                          ( c + cs )
                        | '*' PostAsteriskCommentCharsNoNL:cs -> ( '*' + cs ),
  PostAsteriskCommentCharsNoNL = MultiLineNotForwardSlashOrAsteriskCharNoNL:c
                             (MultiLineCommentCharsNoNL | empty -> ""):cs -> ( c + cs )
                           | '*' PostAsteriskCommentCharsNoNL:cs -> ( '*' + cs ),
  MultiLineNotAsteriskCharNoNL = ~('*') ~LineTerminator SourceCharacter:c -> (c),
  MultiLineNotForwardSlashOrAsteriskCharNoNL = ~('/' | '*') ~LineTerminator SourceCharacter:c -> (c),

  // see section 14.1: Directive Prologues and the Use Strict Directive
  // Some directives (like the Use Strict Directive) may require access to the
  // raw string value, without interpretation of EscapeSequences or LineContinuations
  // @returns the raw string value (not a String Literal AST)
  RawStringLiteral = '"' (RawStringCharacters('"') | empty -> ""):s '"' -> (s)
                   | '\'' (RawStringCharacters("'") | empty -> ""):s '\'' -> (s),
  RawStringCharacters :term = RawStringCharacter(term):c
                                (RawStringCharacters(term) | empty -> ""):cs ->
                              ( c.concat(cs) ),
  RawStringCharacter :term = ~exactly(term) SourceCharacter:s -> (s),
  
  // used by parser to parse actual tokens

  // eat wspace, lineterminators and comments
  // a much more efficient rule than Whitespace | LineTerminator by the above definitions
  WhitespaceOrLineTerminator = char:x ?(ucSpacesRE.test(x)) -> (x), // efficiency shortcut

  skip = (/*WhiteSpace | LineTerminator*/ WhitespaceOrLineTerminator | Comment)*,

  // does not accept LineTerminators, not even implicit ones in a MultiLineComment (cf. section 7.4)
  skipNoLine = (Whitespace | SingleLineComment | MultiLineCommentNoNL)*,

  scanLineTerminator = LineTerminator | ~MultiLineCommentNoNL MultiLineComment,

  // @returns a string
  // As the parser indicates to the lexer what keyword it expects,
  // the scanner does not need a rule listing all possible keywords.
  // The scanner will simply scan any legal identifier name and then
  // check whether the lexed identifier equals the expected keyword name
  // This rule is thus an ad hoc, faster version of the more general rule:
  //   scanKeyword = skip (Keyword | FutureReservedWord(self.strictmode)):t -> (t),
  scanKeyword :kw = skip IdentifierName:n ?(kw === n) -> (kw),
  
  // @returns a string
  // Note: not currently used by the parser, only by the unit tests
  scanPunctuator = skip (Punctuator | DivPunctuator):t -> (t),

  // @returns a string
  // scanPunctNoLineTerminator = skipNoLine // does not accept LineTerminators
  //                            (Punctuator | DivPunctuator):t -> (t),

  // @returns a string
  scanIdentifier = skip Identifier:id -> (id),

  // @returns a string
  scanIdentifierNoLineTerminator = skipNoLine
                                   Identifier:id -> (id),

  // @returns a literal token
  scanLiteral = skip Literal:l -> (l),
  
  // @returns an object {value: string, directive: string}
  // where 'value' contains the interpreted string value
  // and 'directive' contains the uninterpreted ('raw') string value
  scanDirective = skip &(RawStringLiteral):raw StringLiteral:l -> ({value:l.value, directive:raw})
}

// turns an array into a set, represented as a map of elements -> boolean
// to test whether e is in the set s, perform s.e && !Object.prototype.hasProperty(e)
function makeSet(array) {
  var o = {};
  for (var idx = 0; idx < array.length; idx++) {
    o[array[idx]] = true;
  };
  return o;
};

var keywords = makeSet(
 ["break","do","instanceof","typeof","case","else","new","var","catch","finally",
  "return", "void", "continue", "for", "switch", "while", "debugger", "function",
  "this", "with", "default", "if", "throw", "delete", "in", "try" ]);
var nonStrictFutureKws = makeSet(
 ["class", "enum", "extends", "super", "const", "export", "import"]);
var strictFutureKws = makeSet(
 ["implements", "let", "private", "public", "interface", "package",
  "protected", "static", "yield" ]);

LexicalGrammar.isKeyword = function(k) {
  return !!keywords[k] && !Object.prototype.hasProperty(k);
};
LexicalGrammar.isFutureReservedWord = function(k,isStrict) {
  if (isStrict) {
    return  !!(strictFutureKws[k] || nonStrictFutureKws[k]) &&
            !Object.prototype.hasProperty(k);
  } else {
    return !!nonStrictFutureKws[k] &&
            !Object.prototype.hasProperty(k);
  }
};

// === ECMAScript 5 Parser ===

// abstract syntax trees (ASTs) are stored in JSONML format. For details see:
// http://code.google.com/p/es-lab/wiki/JsonMLASTFormat

// this function adds accessors to an AST object,
// making it easier to manipulate the datastructure
// note that these methods will simply be dropped when the AST
// is stringified into a JSONML format
function mixinASTMethods(ast) {
  ast.nodeType = function() { return this[0]; };
  ast.attributes = function() { return this[1] || {}; }; // some leaf nodes may not have attrs
  ast.childAt = function(i) { return this[Number(i)+2]; };
  ast.children = function() { return this.slice(2); };
  return ast;
}

// A.3 Expressions, A.4 Statements and A.5 Functions and Programs
ometa ES5Parser {

  // A.3 Expressions

  // @returns an AST
  PrimaryExpression = k("this") -> (self.ast("ThisExpr", {}, []))
                    | LexicalGrammar.scanIdentifier:id ->
                      (self.ast("IdExpr",{name:id}, []))
                    | LexicalGrammar.scanLiteral:litToken ->
                      ( litToken.type === "regexp"
                        ? self.ast("RegExpExpr",{body:  litToken.value.body,
                                                 flags: litToken.value.flags}, [])
                        : self.ast("LiteralExpr",{type:  litToken.type,
                                                  value: litToken.value}, []) )
                    | ArrayLiteral
                    | ObjectLiteral
                    | "(" Expression(true):e ")" -> (e),

  // @returns an ArrayExpr AST
  ArrayLiteral = "[" ElementList:elts "," (Elision | empty -> []):elis "]" ->
                     ( self.ast("ArrayExpr",{}, elts.concat(elis)) )
               | "[" ElementList:elts "]" ->
                     ( self.ast("ArrayExpr",{}, elts) )
               | "[" (Elision | empty -> []):elis "]" ->
                     ( self.ast("ArrayExpr",{}, elis) ),

  // @returns an array of ASTs
  ElementList = ElementList:elts "," (Elision | empty -> []):elis AssignmentExpression(true):exp ->
                ( elts.concat(elis.concat([ exp ])) )
              | (Elision | empty -> []):elis AssignmentExpression(true):exp ->
                ( elis.concat([exp]) ),

  // @returns an array of ["Empty"] leaf nodes
  Elision = Elision:es "," -> ( es.concat([ self.emptyAst() ]) )
          | "," -> ( [ self.emptyAst() ] ),

  // @returns an ObjectExpr AST
  ObjectLiteral = "{" PropertyNameAndValueList:ps "," "}" ->
                      ( self.ast("ObjectExpr",{},ps) )
                | "{" PropertyNameAndValueList:ps "}" ->
                      ( self.ast("ObjectExpr",{},ps) )
                | "{" "}" -> ( self.ast("ObjectExpr",{},[]) ),

  // @returns an array of ASTs
  PropertyNameAndValueList = PropertyNameAndValueList:ps "," PropertyAssignment:p ->
                             ( ps.concat([ p ]) )
                           | PropertyAssignment:p -> ([ p ]),

  // @returns a *Prop AST
  PropertyAssignment = LexicalGrammar.scanIdentifier:id ?(id == "get") PropertyName:n
                       "(" ")" "{" FunctionBody:body "}" ->
                       ( self.ast("GetterProp",{name:n},
                                  [ self.ast("FunctionExpr",{},
                                             [self.emptyAst(),
                                              self.ast("ParamDecl",{},[])].concat(body)) ]) )
                     | LexicalGrammar.scanIdentifier:id ?(id == "set") PropertyName:n
                       "(" PropertySetParameterList:arg ")" "{" FunctionBody:body "}" ->
                       ( self.ast("SetterProp",{name:n},
                                  [ self.ast("FunctionExpr",{},
                                    [ self.emptyAst(),
                                      self.ast("ParamDecl",{},
                                        [self.ast("IdPatt",{name:arg},[])]) ].concat(body)
                                    )
                                  ]) )
                     | PropertyName:n ":" AssignmentExpression(true):exp ->
                       ( self.ast("DataProp",{name:n},[exp]) ),

  // @returns a string
  PropertyName = LexicalGrammar.scanIdentifier:id -> (id)
               | LexicalGrammar.scanLiteral:l ?(l.type == "string") -> (l.value)
               | LexicalGrammar.scanLiteral:l ?(l.type == "number") -> ( parseFloat(l.value) ),

  // @returns a string (the identifier name)
  PropertySetParameterList = LexicalGrammar.scanIdentifier:id -> (id),

  // @returns an AST
  MemberExpression = k("new") MemberExpression:mexp Arguments:args ->
                     ( self.ast("NewExpr",{},[mexp].concat(args)) )
                   | MemberExpression:mexp "[" Expression(true):iexp "]" ->
                     ( self.ast("MemberExpr",{},[mexp,iexp]) )
                   | MemberExpression:mexp "." LexicalGrammar.scanIdentifier:id ->
                     ( self.ast("MemberExpr",{},[mexp,
                                               self.ast("LiteralExpr",{type:"string",value:id},[])]) )
                   | FunctionExpression
                   | PrimaryExpression,

  // @returns an AST
  NewExpression = MemberExpression
                | k("new") NewExpression:exp -> ( self.ast("NewExpr",{},[exp]) ),

  // @returns an AST
  CallExpression = CallExpression:cexp "[" Expression(true):iexp "]" ->
                   ( self.ast("MemberExpr",{},[cexp,iexp]) )
                 | CallExpression:cexp "." LexicalGrammar.scanIdentifier:id ->
                   ( self.ast("MemberExpr",{},[cexp,
                              self.ast("Literal",{type:"string",value:id},[])]) )
                 | CallExpression:cexp Arguments:args ->
                                 ( self.ast("CallExpr",{},[cexp].concat(args)) )
                 | MemberExpression:mexp Arguments:args ->
                   ( mexp.nodeType() === "MemberExpr"
                     ? self.ast("InvokeExpr",{},mexp.children().concat(args)) :
                       mexp.nodeType() === "IdExpr" && mexp.attributes().name === "eval"
                       // identify possible 'direct call' to eval, cf. 15.1.2.1.1
                       ? self.ast("EvalExpr",{},args) :
                         self.ast("CallExpr",{},[mexp].concat(args)) ),

  // @returns an array of ASTs
  Arguments = "(" ")" -> ([])
            | "(" ArgumentList:args ")" -> (args),

  // @returns an array of ASTs
  ArgumentList = ArgumentList:args "," AssignmentExpression(true):exp ->
                 ( args.concat([ exp ]) )
               | AssignmentExpression(true):exp -> ([ exp ]),

  LeftHandSideExpression = CallExpression | NewExpression,

  PostfixExpression = LeftHandSideExpression:lexp noLineTermPunct("++") ->
                      ( self.ast("CountExpr",{isPrefix:false,op:"++"},[lexp]) )
                    | LeftHandSideExpression:lexp noLineTermPunct("--") ->
                      ( self.ast("CountExpr",{isPrefix:false,op:"--"},[lexp]) )
                    | LeftHandSideExpression,

  UnaryExpression = k("delete")   UnaryExpression:uexp -> ( self.ast("DeleteExpr",{},[uexp]) )
                  | k("void")     UnaryExpression:uexp -> ( self.ast("UnaryExpr",{op:"void"},  [uexp]) )
                  | k("typeof")   UnaryExpression:uexp -> ( self.ast("TypeofExpr",{},[uexp]) )
                  | "++"          UnaryExpression:uexp ->
                    ( self.ast("CountExpr",{isPrefix:true,op:"++"},[uexp]) )
                  | "--"          UnaryExpression:uexp ->
                    ( self.ast("CountExpr",{isPrefix:true,op:"--"},[uexp]) )
                  | noEqDbl("+")  UnaryExpression:uexp -> ( self.ast("UnaryExpr",{op:"+"},[uexp]) )
                  | noEqDbl("-")  UnaryExpression:uexp -> ( self.ast("UnaryExpr",{op:"-"},[uexp]) )
                  | "~"           UnaryExpression:uexp -> ( self.ast("UnaryExpr",{op:"~"},[uexp]) )
                  | noEqChar("!") UnaryExpression:uexp -> ( self.ast("UnaryExpr",{op:"!"},[uexp]) )
                  | PostfixExpression,

  MultiplicativeExpression = MultiplicativeExpression:mexp noEqChar("*")
                               UnaryExpression:uexp ->
                             ( self.ast("BinaryExpr",{op:"*"},[mexp,uexp]) )
                           | MultiplicativeExpression:mexp noEqChar("/") UnaryExpression:uexp ->
                             ( self.ast("BinaryExpr",{op:"/"},[mexp,uexp]) )
                           | MultiplicativeExpression:mexp noEqChar("%") UnaryExpression:uexp ->
                             ( self.ast("BinaryExpr",{op:"%"},[mexp,uexp]) )
                           | UnaryExpression,

  AdditiveExpression = AdditiveExpression:aexp noEqDbl("+") MultiplicativeExpression:mexp ->
					   ( self.ast("BinaryExpr",{op:"+"},[aexp,mexp]) )
				     | AdditiveExpression:aexp noEqDbl("-") MultiplicativeExpression:mexp ->
					   ( self.ast("BinaryExpr",{op:"-"},[aexp,mexp]) )
					 | MultiplicativeExpression,

  ShiftExpression = ShiftExpression:sexp noEq("<<") AdditiveExpression:aexp ->
                    ( self.ast("BinaryExpr",{op:"<<"},[sexp,aexp]) )
                  | ShiftExpression:sexp noEq(">>>") AdditiveExpression:aexp ->
                    ( self.ast("BinaryExpr",{op:">>>"},[sexp,aexp]) )
                  | ShiftExpression:sexp shiftRightPunct AdditiveExpression:aexp ->
                    ( self.ast("BinaryExpr",{op:">>"},[sexp,aexp]) )
                  | AdditiveExpression,

  // Since this grammar assumes OMeta/JS memoizes left-recursive rules,
  // we parametrize RelationalExpression with a boolean "In" flag that
  // signifies whether or not an expression of the form (e1 in e2) is allowed
  RelationalExpression :In = RelationalExpression(In):rexp noEqDbl("<") ShiftExpression:sexp ->
				( self.ast("BinaryExpr",{op:"<"},[rexp,sexp]) )
			  | RelationalExpression(In):rexp noEqDbl(">") ShiftExpression:sexp ->
				( self.ast("BinaryExpr",{op:">"},[rexp,sexp]) )
			  | RelationalExpression(In):rexp "<=" ShiftExpression:sexp ->
				( self.ast("BinaryExpr",{op:"<="},[rexp,sexp]) )
			  | RelationalExpression(In):rexp ">=" ShiftExpression:sexp ->
				( self.ast("BinaryExpr",{op:">="},[rexp,sexp]) )
			  | RelationalExpression(In):rexp k("instanceof") ShiftExpression:sexp ->
				( self.ast("BinaryExpr",{op:"instanceof"},[rexp,sexp]) )
			  | ?(In) RelationalExpression(true):rexp k("in") ShiftExpression:sexp ->
				( self.ast("BinaryExpr",{op:"in"},[rexp,sexp]) )
			  | ShiftExpression,

  EqualityExpression :In =
      EqualityExpression(In):eexp noEq("==") RelationalExpression(In):rexp ->
			( self.ast("BinaryExpr",{op:"=="},[eexp,rexp]) )
		  | EqualityExpression(In):eexp noEq("!=") RelationalExpression(In):rexp ->
			( self.ast("BinaryExpr",{op:"!="},[eexp,rexp]) )
		  | EqualityExpression(In):eexp "===" RelationalExpression(In):rexp ->
			( self.ast("BinaryExpr",{op:"==="},[eexp,rexp]) )
		  | EqualityExpression(In):eexp "!==" RelationalExpression(In):rexp ->
			( self.ast("BinaryExpr",{op:"!=="},[eexp,rexp]) )
		  | RelationalExpression(In),

  BitwiseANDExpression :In = BitwiseANDExpression(In):aexp noEqDbl("&") EqualityExpression(In):eexp ->
						 ( self.ast("BinaryExpr",{op:"&"},[aexp,eexp]) )
					   | EqualityExpression(In),

  BitwiseXORExpression :In = BitwiseXORExpression(In):xexp noEqChar("^") BitwiseANDExpression(In):aexp ->
						 ( self.ast("BinaryExpr",{op:"^"},[xexp,aexp]) )
					   | BitwiseANDExpression(In),
	
  BitwiseORExpression :In = BitwiseORExpression(In):oexp noEqDbl("|") BitwiseXORExpression(In):xexp ->
						 ( self.ast("BinaryExpr",{op:"|"},[oexp,xexp]) )
					   | BitwiseXORExpression(In),
	
  LogicalANDExpression :In = LogicalANDExpression(In):aexp "&&" BitwiseORExpression(In):oexp ->
						 ( self.ast("LogicalAndExpr",{},[aexp,oexp]) )
					   | BitwiseORExpression(In),

  LogicalORExpression :In = LogicalORExpression(In):oexp "||" LogicalANDExpression(In):aexp ->
						( self.ast("LogicalOrExpr",{},[oexp,aexp]) )
					  | LogicalANDExpression(In),

  ConditionalExpression :In = LogicalORExpression(In):oexp "?"
                                AssignmentExpression(In):texp ":" AssignmentExpression(In):fexp ->
                              ( self.ast("ConditionalExpr",{},[oexp,texp,fexp]) )
                            | LogicalORExpression(In),

  AssignmentExpression :In = LeftHandSideExpression:lexp
                           AssignmentOperator:op AssignmentExpression(In):aexp ->
                           ( self.ast("AssignExpr",{op:op},[lexp,aexp]) )
                       | ConditionalExpression(In),

  AssignmentOperator = simpleAssignPunct | ">>>=" | "<<=" | ">>="
                     | "*=" | "/=" | "%=" | "+=" | "-=" | "&=" | "^=" | "|=",

  Expression :In = Expression(In):exp "," AssignmentExpression(In):aexp ->
               ( self.ast("BinaryExpr",{op:","},[exp,aexp]) )
             | AssignmentExpression(In),

  // A.4 Statements

  Statement = Block
            | VariableStatement
            | EmptyStatement
            | ExpressionStatement
            | IfStatement
            | IterationStatement
            | ContinueStatement
            | BreakStatement
            | ReturnStatement
            | WithStatement
            | LabelledStatement
            | SwitchStatement
            | ThrowStatement
            | TryStatement
            | DebuggerStatement,

  // @returns a Block AST
  // Note: the ES5 spec prescribes that a block is a StatementList, not a SourceElements list
  // this precludes nested function declarations
  // This parser explicitly deviates from the spec to enable nested function declarations
  Block = "{" (SourceElements | empty -> []):stmts "}" ->
          ( self.ast("BlockStmt",{},stmts) ),

  // @returns an array of ASTs
  StatementList = StatementList:stmts Statement:stmt ->
                  ( stmts.concat([ stmt ]) )
                | Statement:stmt -> ( [stmt] ),

  // @returns a Var AST
  VariableStatement = k("var") VariableDeclarationList(true):vars sc ->
                      ( self.ast("VarDecl",{},vars) ),

  // @returns an array of ASTs
  VariableDeclarationList :In = VariableDeclarationList(In):vs "," VariableDeclaration(In):v ->
                                ( vs.concat([v]) )
                              | VariableDeclaration(In):v -> ( [v] ),

  // @returns an AST
  VariableDeclaration :In = LexicalGrammar.scanIdentifier:id Initialiser(In):init ->
                            ( self.ast("InitPatt",{},
                                       [self.ast("IdPatt",{name:id},[]),init]) )
                          | LexicalGrammar.scanIdentifier:id -> (self.ast("IdPatt",{name:id}, [])),

  // @returns an AST
  Initialiser :In = simpleAssignPunct AssignmentExpression(In):exp -> ( exp ),

  // @returns an AST
  EmptyStatement = ";" -> ( self.ast("EmptyStmt",{},[]) ), // note: this semicolon eats newlines

  // @returns an Expression AST
  ExpressionStatement = ~("{" | k("function")) Expression(true):exp sc -> ( exp ),

  // @returns an AST
  IfStatement = k("if") "(" Expression(true):bexp ")" Statement:tstmt k("else") Statement:fstmt ->
                ( self.ast("IfStmt",{},[bexp,tstmt,fstmt]) )
              | k("if") "(" Expression(true):bexp ")" Statement:tstmt ->
                ( self.ast("IfStmt",{},[bexp, tstmt, self.ast("EmptyStmt",{},[])]) ),

  // @returns an AST
  IterationStatement = k("do") Statement:s k("while") "(" Expression(true):e ")" sc ->
                       ( self.ast("DoWhileStmt",{},[s,e]) )
                     | k("while") "(" Expression(true):e ")" Statement:s ->
                       ( self.ast("WhileStmt",{},[e,s]) )
                     | k("for") "(" (Expression(false) | empty -> self.emptyAst()):init ";"
                         (Expression(true) | empty -> self.emptyAst()):cond ";"
                         (Expression(true) | empty -> self.emptyAst()):update ")" Statement:s ->
                       ( self.ast("ForStmt",{},[init,cond,update,s]) )
                     | k("for") "(" k("var") VariableDeclarationList(false):vars ";"
                         (Expression(true) | empty -> self.emptyAst()):cond ";"
                         (Expression(true) | empty -> self.emptyAst()):update ")" Statement:s ->
                       ( self.ast("ForStmt",{},[self.ast("VarDecl",{},vars),cond,update,s]) )
                     | k("for") "(" LeftHandSideExpression:lhs k("in")
                          Expression(true):e ")" Statement:s ->
                       ( self.ast("ForInStmt",{},[lhs,e,s]) )
                     | k("for") "(" k("var") VariableDeclaration(false):v k("in")
                          Expression(true):e ")" Statement:s ->
                       ( self.ast("ForInStmt",{},[ self.ast("VarDecl",{},[v]),e,s]) ),

  ContinueStatement = k("continue") sc -> ( self.ast("ContinueStmt",{},[]) )
                    | k("continue") LexicalGrammar.scanIdentifierNoLineTerminator:id sc ->
                      ( self.ast("ContinueStmt",{label:id},[]) ),

  BreakStatement = k("break") sc -> ( self.ast("BreakStmt",{},[]) )
                 | k("break") LexicalGrammar.scanIdentifierNoLineTerminator:id sc ->
                      ( self.ast("BreakStmt",{label:id},[]) ),

  ReturnStatement = k("return") sc ->
                      ( self.ast("ReturnStmt",{},[]) )
                  | k("return") noLineTerminator Expression(true):exp sc ->
                      ( self.ast("ReturnStmt",{},[exp]) ),

  WithStatement = k("with") "(" Expression(true):e ")" Statement:s ->
                  ( self.ast("WithStmt",{},[e,s]) ),

  SwitchStatement = k("switch") "(" Expression(true):e ")" CaseBlock:cases ->
                    ( self.ast("SwitchStmt",{},[e].concat(cases)) ),

  // @return an array of ASTs
  CaseBlock = "{" (CaseClauses | empty -> []):precases DefaultClause:dflt
                  (CaseClauses | empty -> []):postcases "}" ->
                    ( precases.concat([dflt]).concat(postcases) )
            | "{" (CaseClauses | empty -> []):cases "}" -> (cases),

  // @return an array of ASTs
  CaseClauses = CaseClauses:clauses CaseClause:clause -> (clauses.concat([clause]))
              | CaseClause:clause -> ([ clause ]),

  CaseClause = k("case") Expression(true):e ":" (StatementList | empty -> []):stmts ->
               ( self.ast("Case",{},[e].concat(stmts)) ),

  DefaultClause = k("default") ":" (StatementList | empty -> []):stmts ->
                  ( self.ast("DefaultCase",{}, stmts) ),

  LabelledStatement = LexicalGrammar.scanIdentifier:id ":" Statement:s ->
                      ( self.ast("LabelledStmt",{ label: id },[s]) ),

  ThrowStatement = k("throw") noLineTerminator
                              LexicalGrammar.scanLineTerminator ~empty // fails explicitly
                 | k("throw") Expression(true):e sc -> ( self.ast("ThrowStmt",{},[e]) ),

  TryStatement = k("try") Block:b Catch:c Finally:f ->
                 ( self.ast("TryStmt",{},[b,c,f]) )
               | k("try") Block:b Finally:f ->
                 ( self.ast("TryStmt",{},[b,self.emptyAst(),f]) )
               | k("try") Block:b Catch:c ->
                 ( self.ast("TryStmt",{},[b,c]) ),

  // @returns a CatchClause AST
  Catch = k("catch") "(" LexicalGrammar.scanIdentifier:id ")" Block:b ->
          ( self.ast("CatchClause", {},
              [self.ast("IdPatt",{name:id},[]), b]) ),

  // @returns a Block AST
  Finally = k("finally") Block:b -> ( b ),

  DebuggerStatement = k("debugger") sc -> ( self.ast("DebuggerStmt",{},[]) ),

  // A.5 Functions and Programs

  FunctionDeclaration = k("function") LexicalGrammar.scanIdentifier:id
                        "(" (FormalParameterList | empty -> []):formals ")"
                        "{" FunctionBody:body "}" ->
                        ( self.ast("FunctionDecl",{},
                                   [self.ast("IdPatt",{name:id},[]),
                                    self.ast("ParamDecl",{},formals)].concat(body)) ),

  FunctionExpression = k("function") LexicalGrammar.scanIdentifier:id
                       "(" (FormalParameterList | empty -> []):formals ")"
                       "{" FunctionBody:body "}" ->
                       ( self.ast("FunctionExpr",{},
                                  [self.ast("IdPatt",{name:id},[]),
                                   self.ast("ParamDecl",{},formals)].concat(body)) )
                     | k("function") "(" (FormalParameterList | empty -> []):formals ")"
                       "{" FunctionBody:body "}" ->
                       ( self.ast("FunctionExpr",{},
                                  [self.emptyAst(),
                                   self.ast("ParamDecl",{},formals)].concat(body)) ),

  // @returns an array of ASTs
  FormalParameterList = FormalParameterList:formals "," LexicalGrammar.scanIdentifier:id ->
                        ( formals.concat([ self.ast("IdPatt",{name:id},[]) ]) )
                      | LexicalGrammar.scanIdentifier:id -> ([ self.ast("IdPatt",{name:id},[]) ]),

  // @returns an array of ASTs
  FunctionBody = (DirectivePrologue | empty -> []):prologue
                   (SourceElements | empty -> []):src -> ( prologue.concat(src) ),

  Program = (DirectivePrologue | empty -> []):prologue
              (SourceElements | empty -> []):src skipToEnd ->
            ( self.ast("Program",{},prologue.concat(src) ) ),

  // @returns an array of ASTs
  SourceElements = SourceElements:elts SourceElement:e -> ( elts.concat([e]) )
                 | SourceElement:e -> ([e]),

  SourceElement = FunctionDeclaration | Statement,

  // @returns an array of ASTs
  DirectivePrologue = DirectivePrologue:p Directive:d -> ( p.concat([d]) )
                    | Directive:d -> ([d]),
  
  Directive = LexicalGrammar.scanDirective:dir sc -> ( self.ast('PrologueDecl',dir,[]) ),

  // === Implementation-level rules (not part of the spec) ===

  // useful for parsing only expressions and making sure the parser sees all input
  ExpressionOnly = Expression(true):e skipToEnd -> (e),

  // higher-order rule that parses a rule and ensures there is no lingering input
  complete :rule = apply(rule):res skipToEnd -> (res),

  // In OMeta, terms of the syntactic form "name" are translated into
  // an invocation of the 'token' rule, with the text between quotes passed as
  // an argument, i.e. token("name"). In this parser, the term "name" instructs
  // the LexicalGrammar to parse a specific punctuator:
  // token :punct = LexicalGrammar.scanPunctuator:lexed ?(punct == lexed) -> (punct),

  // The above scanPunctuator rule turns out to be one of the main bottlenecks
  // of the parsing process, so we replace it by a set of more efficient rules:
  // given that the parser can already indicate what punctuator it is interested in,
  // the parser just instructs the lexer to skip whitespace, then tries to match
  // exactly the characters it expects. This works for all punctuators that are not
  // the prefix of another punctuator:
  // ``>>>='' |``>>='' | ``==='' | ``!==''| ``<<=''| ``/=''
  // ``+=''   | ``-='' | ``*=''  | ``%='' | ``>='' | ``++'' |
  // ``--''   | ``<='' | ``&=''  | ``|='' | ``^='' | ``&&'' |
  // ``||''   | '{'    | '}'     | '('    | ')'    | '['    | ']' |
  // '.'      | ';'    | ','     | '~'    | '?'    | ':'
  token :punct = LexicalGrammar.skip seq(punct) -> (punct),

  // for all other punctuators, an additional check is required to
  // distinguish the punctuator from a longer punctuator with the same prefix

  //``>>'' 	avoid: >>> >>>=
  shiftRightPunct = LexicalGrammar.skip ``>>'' ~'>' -> (">>"),

  //'='  	  avoid: == ===
  simpleAssignPunct = LexicalGrammar.skip '=' ~'=' -> ("="),

  //``=='' 	avoid: ===				
  //``!='' 	avoid: !==				
  //``>>>'' avoid: >>>=
  //``<<''  avoid: <<=
  // no Compare or Assignment Punctuator
  noEq :t = LexicalGrammar.skip seq(t) ~'=' -> (t),

  //'!'  	  avoid: != !==		
  //'*' 	  avoid: *=				
  //'%' 	  avoid: %=				
  //'^'  	  avoid: ^=
  //'/'     avoid: /=
  // no Compare or Assignment Single-character Punctuator
  noEqChar :t = LexicalGrammar.skip exactly(t) ~'=' -> (t),

  //  '&'  	avoid: &= &&		
  //  '|'  	avoid: |= ||		
  //  '<'  	avoid: <= << <<=	
  //  '>'   avoid: >= >> >>> >>>=
  //  '+' 	avoid: += ++		
  //  '-' 	avoid: -= --			
  // no Assignment single-character punctuator (excludes doubles)
  noEqDbl :t = LexicalGrammar.skip exactly(t) ~'=' ~exactly(t) -> (t),

  // a variant of the 'token' rule that does not accept line terminators
  // before it reaches the token. Only used for '++' and '--' so it's safe
  // to simply match the token using 'seq' without further checks
  //noLineTermPunct :punct = foreign(LexicalGrammar, 'scanPunctNoLineTerminator'):lexed
  //                        ?(lexed == punct) -> (punct),
  noLineTermPunct :punct = LexicalGrammar.skipNoLine seq(punct) -> (punct),

  // k(kw) parses an expected keyword
  k :kw = LexicalGrammar.scanKeyword(kw),

  noLineTerminator = LexicalGrammar.skipNoLine,

  skipToEnd = LexicalGrammar.skip end,

  sc = noLineTerminator ';' // Note: don't use ";" as this is equivalent to token(";")
                            // which would allow line terminators to be eaten as well
     | noLineTerminator (LexicalGrammar.scanLineTerminator | end | &'}')
       // a semicolon is "automatically inserted" if a newline is reached,
       // the end of the input stream is reached, or the offending token is '}'

}
ES5Parser.initialize = function() {
  this.strictmode = false;

  // this function is used to construct ASTs
  this.ast = function(type, attributes, children) {
    return mixinASTMethods([ type, attributes ].concat(children));
  };
  this.emptyAst = function() {
    return mixinASTMethods([ "Empty" ]);
  };
};
// indicate to OMeta to memoize parameterized rules
// this is crucial for the ES5 Parser, as many of its *Expression
// rules are left-recursive and parameterized with a boolean parameter
// indicating whether an "in-expression" is allowed or not.
// see http://tinlizzie.org/ometa-js/#Memoizing_Parameterized_Rules
ES5Parser.memoizeParameterizedRules();